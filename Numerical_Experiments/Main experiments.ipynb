{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Adaptive Exponential Weights Algorithm for <br/> Learning Equilibrium Flows of the Routing Game</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import networkx as nx   # best working with networkx 2.5 to avoid errors\n",
    "from scipy import integrate\n",
    "import os\n",
    "current_dir = os.getcwd()\n",
    "import pickle\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Preliminary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminary function to import edge data:\n",
    "def read_edge(network_name):\n",
    "    netfile = os.path.join(root, network_name,network_name + '_net.tntp')\n",
    "    net = pd.read_csv(netfile, skiprows=8, sep='\\t')\n",
    "    trimmed= [s.strip().lower() for s in net.columns]\n",
    "    net.columns = trimmed\n",
    "    # And drop the silly first andlast columns\n",
    "    net.drop(['~', ';'], axis=1, inplace=True)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to generate random noises given a network and a time horizon:\n",
    "def generate_noise(network,T,bound_noise_rel=1,StdDevNoise_abs=10):\n",
    "    network_noise = nx.DiGraph(T=T)\n",
    "    network_noise.add_edges_from(list(network.edges()))\n",
    "    for e in network_noise.edges():\n",
    "        network_noise[e[0]][e[1]]['noise_rel'] = bound_noise*np.random.uniform(-1,1,T+1)\n",
    "        network_noise[e[0]][e[1]]['noise_abs'] =  np.random.normal(0,StdDevNoise_abs,T+1)\n",
    "    return network_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the costs on all edges of the network (already assigned flows and exo_load) \n",
    "def compute_e_cost(network,edges):\n",
    "    for e_index in range(len(edges)):        #for each edge in the network\n",
    "        # Import edges data\n",
    "        e_head = edges['init_node'][e_index]\n",
    "        e_tail = edges['term_node'][e_index]\n",
    "        free_flow = edges['free_flow_time'][e_index]\n",
    "        B =  edges['b'][e_index]\n",
    "        Power =  edges['power'][e_index]\n",
    "        capacity =  edges['capacity'][e_index]\n",
    "#         #Define the BPR function\n",
    "        term = (network[e_head][e_tail]['load'] )/capacity\n",
    "        e_cost = free_flow * ( 1 + B * (term**Power)) *(1+ network[e_head][e_tail]['noise_rel'])       #Multiplicative noise\n",
    "        e_cost += network[e_head][e_tail]['noise_abs']\n",
    "        network[e_head][e_tail]['cost'] = e_cost\n",
    "    return\n",
    "\n",
    "# Compute the costs on a path [i,p] of the network (alredy assigned flows and exo_load) \n",
    "def p_cost(network,Paths,i,p):\n",
    "    path_p = Paths[i][p]\n",
    "    cost = 0\n",
    "    for node in range(len(path_p) -1):\n",
    "        e_head=path_p[node]\n",
    "        e_tail = path_p[node+1]\n",
    "        if 'cost' not in network[e_head][e_tail]: network[e_head][e_tail]['cost'] =0  # In case, cost has not been generated\n",
    "        cost+= network[e_head][e_tail]['cost']\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(network,flow): \n",
    "    for e in network.edges():\n",
    "        edge = network[e[0]][e[1]]\n",
    "        edge['load']= 0  #initialize the load on edge\n",
    "        if 'passing_paths' in edge:\n",
    "            for pair_path in edge['passing_paths']:\n",
    "                i = pair_path[0]\n",
    "                p = pair_path[1]\n",
    "                edge['load']+= flow[i][p]\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### the MEAN Potential function with Beta-distribution noise\n",
    "def potential(flow,pairs,network,edges, mean_noise):\n",
    "    load(network,flow)\n",
    "    Out = 0  #Initialize output\n",
    "    for e_index in range(len(edges)):        #for each edge in the network\n",
    "        # Import edges data\n",
    "        e_head = edges['init_node'][e_index]\n",
    "        e_tail = edges['term_node'][e_index]\n",
    "        free_flow = edges['free_flow_time'][e_index]\n",
    "        B =  edges['b'][e_index]\n",
    "#         Power =  edges['power'][e_index]\n",
    "        Power =1\n",
    "        capacity =  edges['capacity'][e_index]\n",
    "        if 'load' not in network[e_head][e_tail]:  network[e_head][e_tail]['load'] =  0\n",
    "        if 'exo_load' not in network[e_head][e_tail]:  network[e_head][e_tail]['exo_load'] =  0\n",
    "        #Define the BPR function\n",
    "        def latency(x):\n",
    "            return free_flow * ( 1 + B * ((x/capacity)**Power) )\n",
    "        # The potential value (with mean_noise = 0):\n",
    "        Out+= integrate.quad(latency, 0, network[e_head][e_tail]['load'])[0]    \n",
    "    return Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to store the results:\n",
    "def save_output(directory, outputEW=[],outputAcceEW=[],outputAdaEW=[]):\n",
    "    if len(outputEW) >0:\n",
    "        with open(directory+'outputEW.data', 'wb') as filehandle:\n",
    "            pickle.dump(outputEW, filehandle)   \n",
    "    if len(outputAcceEW) >0:\n",
    "        with open(directory+'outputAcceEW.data', 'wb') as filehandle:\n",
    "            pickle.dump(outputAcceEW, filehandle)   \n",
    "    if len(outputAdaEW) >0:\n",
    "        with open(directory+'outputAdaEW.data', 'wb') as filehandle:\n",
    "            pickle.dump(outputAdaEW, filehandle)   \n",
    "def save_potential(directory,potEW=[],potAcceEW=[],potAdaEW=[]):\n",
    "    if len(potEW)>0:\n",
    "        dfEW = pd.DataFrame({'potEW':potEW})\n",
    "        dfEW.to_csv(directory+'potEW.csv', index=False)\n",
    "    if len(potAcceEW)>0:\n",
    "        dfAcceEW = pd.DataFrame({'potAcceEW':potAcceEW})\n",
    "        dfAcceEW.to_csv(directory+'potAcceEW.csv', index=False)\n",
    "    if len(potAdaEW)>0:\n",
    "        dfAdaEW = pd.DataFrame({'potAdaEW':potAdaEW})\n",
    "        dfAdaEW.to_csv(directory+'potAdaEW.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Networks Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can input a network instance by the following syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_name = 'SiouxFalls'\n",
    "# network_name = 'Austin'\n",
    "# network_name = 'Eastern-Massachusetts'\n",
    "# network_name = 'Braess-Example'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.path.dirname(os.path.abspath('.'))     #Look for the root folder\n",
    "root = root+'\\\\TransportationNetworks-master'\n",
    "directory = current_dir + \"/data/\"+ network_name + '/'\n",
    "os.makedirs(os.path.dirname(directory), exist_ok=True)\n",
    "directory_sol =  current_dir + \"/solutions/\"+ network_name + '/'\n",
    "os.makedirs(os.path.dirname(directory_sol), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) We choose an instance (generated via Passing_data_to_gpickle.ipynb):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pairs =  5\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 24\n",
      "Number of edges: 76\n",
      "Average in degree:   3.1667\n",
      "Average out degree:   3.1667\n",
      "Number of paths =  50\n"
     ]
    }
   ],
   "source": [
    "N = 5 ## Choose the number of pairs:\n",
    "print('Number of pairs = ', N)\n",
    "## Load the network:\n",
    "network= nx.read_gpickle(directory +\"/graph,N=\"+str(N)+ \".gpickle\")      \n",
    "print(nx.info(network))                               \n",
    "pairs = pd.read_csv(directory+'pairs,N='+str(N)+'.csv')\n",
    "\n",
    "edges = read_edge(network_name) ## Load the edges data:\n",
    "## Load the path data:\n",
    "with open(directory+'paths,N='+str(N)+'.data', 'rb') as filehandle:\n",
    "    paths = pickle.load(filehandle) \n",
    "Num_p = 0\n",
    "for i in range(N):\n",
    "    Num_p+= len(paths[i])\n",
    "print('Number of paths = ', Num_p) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Exponential Weight Algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ouput of this algorithm is a class, called ```solution```, where:\n",
    "* ```solution.pot``` is a $T_\\textrm{term}$ dimensional list of values of $\\Phi(F[t])$ for $t=1,...,T_\\textrm{term}$; where $T_\\textrm{term}$ is the time the algorithm terminates. \n",
    "* ```solution.flag``` shows the termination condition/ error flag. The list of flags are: ```'Normal execute'```, ```'Terminate due to \"output_t = NaN\"'``` (if this is the case, should reduce stepsize)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EW(pairs,network,paths,edges,T,network_noise,mean_noise,stoch = True, fixed_stepsize=False, stepsize=1, save_output = False):     #Include the input paths (pre-computed to save computations)\n",
    "    print('#----------------------------------','\\n','Run EW algorithm with T = ', T, ', stochastic = ', stoch)\n",
    "    # Checking conditions of inputs:\n",
    "    if not (len(pairs)== len(paths)):\n",
    "        print('Error: inconsistent dimensions of pairs and paths')\n",
    "        return\n",
    "    if (stoch==True ) and ((network.number_of_edges()!= network_noise.number_of_edges()) or (T != network_noise.graph['T'])):\n",
    "        print('Error: inconsistent data in network_noise')\n",
    "        return    \n",
    "    N=len(pairs)   \n",
    "    #INITIALIZATIONS\n",
    "    flag = 'Normal execute'\n",
    "    error = 0 \n",
    "    pot = []\n",
    "    outputXt = []\n",
    "    output= []\n",
    "    ## Create for a zeros vector\n",
    "    zeros=[]\n",
    "    for i in range(N):\n",
    "        zeros.append(np.zeros(len(paths[i])))\n",
    "    ### Initialize Y at zeros\n",
    "    Y = copy.deepcopy(zeros)\n",
    "    X_cumul = copy.deepcopy(zeros)\n",
    "    # Reset the noise on each edge:    \n",
    "    for e_index in range(len(edges)):\n",
    "        e_head = edges['init_node'][e_index]\n",
    "        e_tail = edges['term_node'][e_index]\n",
    "        network[e_head][e_tail]['noise_rel']=0\n",
    "        network[e_head][e_tail]['noise_abs']=0\n",
    "        network[e_head][e_tail]['exo_load']=0\n",
    "        \n",
    "                    #-----------------------------------------------------------#\n",
    "                    #                  START OF MAIN ALGORITHM                  #\n",
    "                    #-----------------------------------------------------------#\n",
    "    for t in range(1,T+1):\n",
    "        if (t % 500 ==1): print('t=',t)    #To check the algorithm is running\n",
    "        if (t==T): print('T_terminal=',t)\n",
    "        #-----------------------------------------------\n",
    "        #     Start computing Xt (the output at time t)\n",
    "        #-----------------------------------------------\n",
    "        Xt=[]\n",
    "        X_avg=[]\n",
    "        for i in range(N):\n",
    "            Xti,X_avg_i = [],[]\n",
    "            for p in range(len(paths[i])):\n",
    "#                 if t==1: print('This is Y[i] = ', np.array(Y[i]))\n",
    "                Xtip = float(pairs['demand'][i]) / float(np.sum( np.exp(np.array(Y[i]) - float(Y[i][p]))))\n",
    "                Xti.append(Xtip)\n",
    "                X_cumul[i][p] += Xtip\n",
    "                X_avg_i.append(float(X_cumul[i][p])/t)\n",
    "            #Finish computing Xi\n",
    "            if np.isnan(np.sum(Xti)):   #IF there exists an NaN in Xi, then terminate\n",
    "                flag = 'Terminate due to \"output_t = NaN\"'\n",
    "                print('T_terminate=',t)\n",
    "                error =1\n",
    "                break\n",
    "            Xt.append(Xti)\n",
    "            X_avg.append(X_avg_i)\n",
    "        if (error ==1): break     #If there exist NaN in Xi; then break and terminate\n",
    "        # Finish computing and store X_avg\n",
    "        if save_output==True: \n",
    "            output.append(X_avg)\n",
    "            outputXt.append(Xt)\n",
    "        \n",
    "        \n",
    "      \n",
    "        #----------------------------------------------\n",
    "        #     Generate exogeneous_load if stoch= True\n",
    "        #---------------------------------------------\n",
    "        if stoch == True:\n",
    "            for e_index in range(len(edges)):\n",
    "                e_head = edges['init_node'][e_index]\n",
    "                e_tail = edges['term_node'][e_index]\n",
    "                network[e_head][e_tail]['noise_rel']= network_noise[e_head][e_tail]['noise_rel'][t]    #load the exo_load from network_noise to network\n",
    "                network[e_head][e_tail]['noise_abs']= network_noise[e_head][e_tail]['noise_abs'][t]    #load the exo_load from network_noise to network\n",
    "        \n",
    "        #--------------------------------------------------------------\n",
    "        #     Compute potential value for storing purposes\n",
    "        #---------------------------------------------------------------\n",
    "        load(network,X_avg)                       # Import load at X_avg to network         \n",
    "        pot.append( potential(X_avg,pairs,network,edges, mean_noise)) # Store the potential of X_avg\n",
    "        #IF we want to compare performance of Xt\n",
    "#         potXt.append(potential(Xt,pairs,network,edges)) # Store the potential of X_avg\n",
    "    \n",
    "        #----------------------------------------------------\n",
    "        #      Updating the weight Y\n",
    "        #---------------------------------------------------\n",
    "        load(network,Xt)                       # Import load at Xt to network to compute cost        \n",
    "        compute_e_cost(network,edges)             #Generate the corresponding costs on all edges:\n",
    "        if fixed_stepsize == False:\n",
    "            for i in range(N):\n",
    "                for p in range(len(paths[i])):\n",
    "                    Y[i][p] = Y[i][p] - stepsize* (1/np.sqrt(t)) * p_cost(network,paths,i,p)\n",
    "        else: \n",
    "            for i in range(N):\n",
    "                for p in range(len(paths[i])):\n",
    "                    Y[i][p] = Y[i][p] - stepsize * p_cost(network,paths,i,p)\n",
    "    \n",
    "    class solution:\n",
    "        def __init__(self,pot,output,outputXt,flag):\n",
    "            self.output = output\n",
    "            self.outputXt = outputXt\n",
    "            self.pot = pot\n",
    "#             self.potXt = potXt\n",
    "            self.flag= flag        \n",
    "    return solution(pot,output,outputXt,flag)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Accelerated Exponential Weights Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ```beta``` = a constant which should be chosen as an upper-bound of the smoothness level of the latency functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AcceEW(pairs,network,paths,edges,T,network_noise,mean_noise,beta,stoch,save_output=False):    \n",
    "    print('#----------------------------------','\\n','Run AcceWeight algorithm with T = ', T, ', stochastic = ', stoch)\n",
    "    # Checking conditions of inputs:\n",
    "    if not (len(pairs)== len(paths)):\n",
    "        print('Error: inconsistent dimensions of pairs and paths')\n",
    "        return\n",
    "    if (stoch==True ) and ((network.number_of_edges()!= network_noise.number_of_edges()) or (T != network_noise.graph['T'])):\n",
    "        print('Error: inconsistent data in network_noise')\n",
    "        return     \n",
    "    N=len(pairs)\n",
    "    #INITIALIZATIONS\n",
    "    pot = []\n",
    "    output = []\n",
    "    flag = 'Normal execute'\n",
    "    error = 0\n",
    "    #Initialize stepsizes:\n",
    "    alpha = 0\n",
    "    gamma0 = 1/(N* max(pairs['demand']) *beta)\n",
    "    gamma = gamma0\n",
    "    # Initialization for Xt, Y, Z_tilde,Zt\n",
    "    zeros=[]\n",
    "    for i in range(N):\n",
    "        zeros.append(np.zeros(len(paths[i])))\n",
    "    ### Initialize Y,Zt,Z_tilde at zeros\n",
    "    Y = copy.deepcopy(zeros)\n",
    "    Zt= copy.deepcopy(zeros)\n",
    "    Xt= copy.deepcopy(zeros)\n",
    "  \n",
    "    for e_index in range(len(edges)):\n",
    "        e_head = edges['init_node'][e_index]\n",
    "        e_tail = edges['term_node'][e_index]\n",
    "        network[e_head][e_tail]['noise_rel']=0\n",
    "        network[e_head][e_tail]['noise_abs']=0\n",
    "        network[e_head][e_tail]['exo_load']=0\n",
    "        \n",
    "                            #-----------------------------------------------------#\n",
    "                            #              START OF MAIN ALGORITHM                #\n",
    "                            #-----------------------------------------------------#\n",
    "    for t in range(1,T+1):\n",
    "        if (t % 500 ==1): print('t=',t)    #To check the algorithm is running\n",
    "        if (t==T): print('T_terminal=',t)        \n",
    "        #----------------------------------------#\n",
    "        #         Compute Zt                     #\n",
    "        #----------------------------------------#       \n",
    "        X_prev = copy.deepcopy(Xt)\n",
    "        Xt=[]\n",
    "        for i in range(N):\n",
    "            Xt_i=[]\n",
    "            for p in range(len(paths[i])):\n",
    "                diff = np.sum(np.exp(np.array(Y[i]) - Y[i][p]))\n",
    "                Zt[i][p] = float(pairs['demand'][i])/  diff\n",
    "                Xt_ip = alpha*X_prev[i][p]  + (1-alpha)* Zt[i][p]\n",
    "                Xt_i.append(Xt_ip)     #Compute X_ip and append it into Xi array\n",
    "            # Checking error in computing Zi\n",
    "            if np.isnan(np.sum(Zt[i])):   #IF there exists an NaN in Fi, then terminate\n",
    "                flag = 'Terminate due to \"output_t = NaN\"'\n",
    "                print('T_terminate=',t)\n",
    "                error =1\n",
    "                break\n",
    "            Xt.append(Xt_i)\n",
    "        if (error ==1): break     #If there exist NaN in Fi; then break and terminate   \n",
    "        ####### To store output\n",
    "        if save_output==True:\n",
    "            output.append(Xt)         #Store the output Xt\n",
    "\n",
    "        #----------------------------------------------#\n",
    "        #     Generate exogeneous_load if stoch= True  #\n",
    "        #----------------------------------------------#\n",
    "        if stoch == True:\n",
    "            for e_index in range(len(edges)):\n",
    "                e_head = edges['init_node'][e_index]\n",
    "                e_tail = edges['term_node'][e_index]\n",
    "                network[e_head][e_tail]['noise_rel'] = network_noise[e_head][e_tail]['noise_rel'][t]\n",
    "                network[e_head][e_tail]['noise_abs'] = network_noise[e_head][e_tail]['noise_abs'][t]\n",
    "#         #--------------------------------------------------#\n",
    "#         #     Compute potential value for plotting purpose #\n",
    "#         #--------------------------------------------------#     \n",
    "        load(network,Xt)                               #Import the load at Xt to the network\n",
    "        pot.append(potential(Xt,pairs,network,edges,mean_noise))  #Compute the rosenthal value of Xt\n",
    "        \n",
    "        #----------------------------------------#\n",
    "        #        Update alpha and gamma          #\n",
    "        #----------------------------------------#\n",
    "        gamma_prev = gamma\n",
    "        gamma = ((2*gamma_prev + gamma0) + np.sqrt( 4*gamma_prev * gamma0 + (gamma0**2) )   )/2\n",
    "        alpha = gamma_prev/gamma\n",
    "        \n",
    "        #----------------------------------------#\n",
    "        #         Compute Z_tilde              #\n",
    "        #----------------------------------------#\n",
    "        Z_tilde=[]\n",
    "        for i in range(N):\n",
    "            Z_tilde_i = []\n",
    "            for p in range(len(paths[i])):\n",
    "                Z_tilde_ip = alpha *  Xt[i][p] + (1-alpha) * Zt[i][p]\n",
    "                Z_tilde_i.append(Z_tilde_ip)\n",
    "            Z_tilde.append(Z_tilde_i)\n",
    "        #----------------------------------------------------\n",
    "        #      Updating the weight Y\n",
    "        #---------------------------------------------------\n",
    "        load(network,Z_tilde)                          #Import the load in network at Z_tilde\n",
    "        compute_e_cost(network,edges)                  #Re-compute the corresponding edges-costs at Z_tilde\n",
    "        for i in range(N):\n",
    "            for p in range(len(paths[i])):\n",
    "                Y[i][p] = Y[i][p] - (1-alpha)*gamma * p_cost(network,paths,i,p)   \n",
    "    \n",
    "    class solution:\n",
    "        def __init__(self,output, pot, flag):\n",
    "            self.output = output\n",
    "            self.pot = pot\n",
    "            self.flag= flag\n",
    "    return solution(output,pot,flag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Adaptive Exponential Weights Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaEW(pairs,network,paths,edges,T, theta,network_noise,mean_noise,stoch = True, gamma1=0,save_output=False):     #Include the input paths (pre-computed to save computations)\n",
    "    print('#----------------------------------','\\n','Run AdaWeight algorithm with T = ', T, ', stochastic = ', stoch)\n",
    "    # Checking conditions of inputs:\n",
    "    if not (len(pairs)== len(paths)):\n",
    "        print('Error: inconsistent dimensions of pairs and paths')\n",
    "        return\n",
    "    if (stoch==True ) and ((network.number_of_edges()!= network_noise.number_of_edges()) or (T != network_noise.graph['T'])):\n",
    "        print('Error: inconsistent data in network_noise')\n",
    "        return     \n",
    "    N=len(pairs)\n",
    "    #INITIALIZATIONS\n",
    "    output = []\n",
    "    pot = []\n",
    "    error = 0\n",
    "    flag = 'Normal execute'\n",
    "    #Initialize stepsizes:\n",
    "    psi = 0\n",
    "    gamma = gamma1     # If gamma1=0, we have the same initial point (logit at Y=0) as other algorithms\n",
    "    \n",
    "    # Initialization \n",
    "     ## Create for a zeros vector\n",
    "    zeros=[]\n",
    "    for i in range(N):\n",
    "        zeros.append(np.zeros(len(paths[i])))\n",
    "    ### Initialize Y at zeros\n",
    "    Y = copy.deepcopy(zeros)\n",
    "    Y_half=copy.deepcopy(zeros)\n",
    "    S=copy.deepcopy(zeros)\n",
    "    for e_index in range(len(edges)):\n",
    "        e_head = edges['init_node'][e_index]\n",
    "        e_tail = edges['term_node'][e_index]\n",
    "        network[e_head][e_tail]['noise_rel']=0\n",
    "        network[e_head][e_tail]['noise_abs']=0\n",
    "        network[e_head][e_tail]['exo_load']=0\n",
    "                    #------------------------------------------#\n",
    "                    #         START OF MAIN ALGORITHM          #\n",
    "                    #------------------------------------------#\n",
    "    for t in range(1,T+1):\n",
    "        if (t % 500 ==1): print('t=',t)    #To check the algorithm is running\n",
    "        if (t==T): print('T_terminal=',t)\n",
    "        #-------------------------------------\n",
    "        #       Computing Z , Z_bar\n",
    "        #----------------------------------\n",
    "        Z_bar = []\n",
    "        for i in range(N):\n",
    "            Z_bar_i = []\n",
    "            for p in range(len(paths[i])):\n",
    "                diff = np.sum(np.exp(gamma* np.array(Y[i]) - gamma* Y[i][p]))\n",
    "                Zip =  float(pairs['demand'][i]) / float(diff)\n",
    "                Z_bar_i.append( (2/ (t*(t+1))) * ( t* Zip + S[i][p]  ) )\n",
    "            Z_bar.append(Z_bar_i)\n",
    "        #----------------------------------------------\n",
    "        #     Generate exogeneous_load if stoch= True\n",
    "        #---------------------------------------------\n",
    "        if stoch == True:\n",
    "            for e_index in range(len(edges)):\n",
    "                e_head = edges['init_node'][e_index]\n",
    "                e_tail = edges['term_node'][e_index]\n",
    "                network[e_head][e_tail]['noise_rel']= network_noise[e_head][e_tail]['noise_rel'][t]    #load the exo_load from network_noise to network\n",
    "                network[e_head][e_tail]['noise_abs']= network_noise[e_head][e_tail]['noise_abs'][t]\n",
    "                \n",
    "        #------------------------------------------\n",
    "        #        Cost at Z_bar and update Y_half\n",
    "        #-------------------------------------------\n",
    "        load(network,Z_bar)         # Import network with load at Z_bar\n",
    "        compute_e_cost(network,edges)                  #Re-compute the corresponding edges-costs at Z_bar\n",
    "        C_Z_bar=[]\n",
    "        for i in range(N):\n",
    "            C_Z_bar_i=[]\n",
    "            for p in range(len(paths[i])):\n",
    "                cost_Z_bar_ip = p_cost(network,paths,i,p) \n",
    "                C_Z_bar_i.append(cost_Z_bar_ip )\n",
    "                Y_half[i][p] = Y[i][p] - (t * cost_Z_bar_ip )\n",
    "            C_Z_bar.append(C_Z_bar_i)\n",
    "                \n",
    "        #---------------------------------------\n",
    "        #        Computing Z_half and Xt\n",
    "        #---------------------------------------\n",
    "        Xt = []\n",
    "        for i in range(N):\n",
    "            Xt_i = []\n",
    "            for p in range(len(paths[i])):\n",
    "                diff = np.sum(np.exp(gamma* np.array(Y_half[i]) - gamma*Y_half[i][p]))\n",
    "                Z_half_ip  = float(pairs['demand'][i])/ float(diff)\n",
    "                Xt_ip = ((2/ (t*(t+1))) * (t* Z_half_ip + S[i][p]  ) )\n",
    "                S[i][p] = S[i][p] + t* Z_half_ip\n",
    "                Xt_i.append(Xt_ip)\n",
    "            Xt.append(Xt_i)\n",
    "        \n",
    "    \n",
    "        ##------------------------------\n",
    "        ##   Store result\n",
    "        #-------------------------------\n",
    "        if save_output==True:\n",
    "            output.append(Xt)\n",
    "        \n",
    "        #---------------------------------------------\n",
    "        # Compute potential at Xt for plotting purpose\n",
    "        #---------------------------------------------\n",
    "        load(network,Xt)                               #Import the load at Xt to the network\n",
    "        pot.append(potential(Xt,pairs,network,edges,mean_noise))  #Compute the rosenthal value of Xt\n",
    "\n",
    "        #-------------------------------------\n",
    "        #        Update Y and S, psi and gamma              \n",
    "        #-------------------------------------\n",
    "        compute_e_cost(network,edges)                  #Re-compute the corresponding edges-costs at Xt\n",
    "        norm_infty = 0\n",
    "        for i in range(N):\n",
    "            for p in range(len(paths[i])):\n",
    "                cost_Xt_i_p = p_cost(network,paths,i,p) \n",
    "                Y[i][p] = Y[i][p] - (t *  cost_Xt_i_p )\n",
    "                if np.abs(cost_Xt_i_p - C_Z_bar[i][p]) > norm_infty: norm_infty= np.abs(cost_Xt_i_p - C_Z_bar[i][p])\n",
    "        psi = psi + (t**2) * (norm_infty**2)\n",
    "        gamma = 1 / (np.sqrt(theta + psi))\n",
    "        \n",
    "#         print('Z_bar = ', Z_bar, '\\n','Xt = ', Xt, '\\n','S=',S)\n",
    "    class solution:\n",
    "        def __init__(self,output, pot,  flag):\n",
    "            self.output = output\n",
    "            self.pot = pot\n",
    "            self.flag= flag\n",
    "            \n",
    "    return solution(output,pot,flag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. NUMERICAL EXPERIMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1. STATIONARY SETTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------------------- \n",
      " Run AcceWeight algorithm with T =  1000 , stochastic =  False\n",
      "t= 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:50: RuntimeWarning: overflow encountered in exp\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:87: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t= 501\n",
      "T_terminal= 1000\n",
      "#---------------------------------- \n",
      " Run AdaWeight algorithm with T =  1000 , stochastic =  False\n",
      "t= 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:83: RuntimeWarning: overflow encountered in exp\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:48: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t= 501\n",
      "T_terminal= 1000\n",
      "#---------------------------------- \n",
      " Run EW algorithm with T =  1000 , stochastic =  False\n",
      "t= 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:47: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t= 501\n",
      "T_terminal= 1000\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------------------\n",
    "#         STOCHASTIC\n",
    "#-----------------------------------------------------------------------------------------\n",
    "#-----------------------------------\n",
    "# Choose a regime\n",
    "#-----------------------------------\n",
    "regime = 'stationary'\n",
    "\n",
    "#-----------------------------------\n",
    "#  Choose the beta\n",
    "#-----------------------------------\n",
    "betas = [0.001]        # the parameter beta (smoothness approximation) of AcceleWeight\n",
    "T=1000                 # the learning horizon\n",
    "theta=100              # a parameter to control the initial stepsize of AdaWeight (can be set to 1).\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "# Pre-generate and store random exo-load to data/network_name/noise.gpickle\n",
    "#----------------------------------------------------------\n",
    "if regime=='stationary': \n",
    "    Stoch = False\n",
    "    network_noise = []\n",
    "    mean_noise = 0\n",
    "else: \n",
    "    Stoch=True\n",
    "\n",
    "#----------------------------\n",
    "# Run AcceEW algorithm\n",
    "#-------------------------       \n",
    "for beta in betas:\n",
    "    folder = directory_sol + '/'+ regime+ '/N='+str(N)+', T='+str(T)+ ', beta = ' + str(beta)+ '/'\n",
    "    os.makedirs(os.path.dirname(folder), exist_ok=True)        \n",
    "    SolAcceEW = AcceEW(pairs,network,paths,edges,T,network_noise,mean_noise,beta,stoch = Stoch) \n",
    "    save_potential(folder, potAcceEW=SolAcceEW.pot)      #save the potential values\n",
    "\n",
    "# #------------------------------------------------------------------------------------\n",
    "beta_best = 0.001       #beta_best = an \"address\" for saving results of ExpWeight and AdaWeight. Normally, we save the results of ExpWEight and ADaWeight to the same folder of AcceleWeight (with beta parameter = beta_best)\n",
    "folder = directory_sol + '/'+ regime+ '/N='+str(N)+', T='+str(T)+ ', beta = ' + str(beta_best)+ '/'\n",
    "#-----------------------\n",
    "# Run AdaEW algorithm\n",
    "#-------------------------\n",
    "SolAdaEW= AdaEW(pairs,network,paths,edges,T, theta,network_noise,mean_noise,stoch = Stoch, gamma1=0)  \n",
    "save_potential(folder, potAdaEW=SolAdaEW.pot)      #save the potential values\n",
    "#-----------------------\n",
    "# Run EW algorithm\n",
    "#-------------------------\n",
    "SolEW= EW(pairs,network,paths,edges,T,network_noise,mean_noise,stoch = Stoch, fixed_stepsize=False, stepsize=1)\n",
    "save_potential(folder, potEW=SolEW.pot)      #save the potential values\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. STOCHASTIC SETTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------------------- \n",
      " Run AdaWeight algorithm with T =  1000 , stochastic =  True\n",
      "t= 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:83: RuntimeWarning: overflow encountered in exp\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:48: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t= 501\n",
      "T_terminal= 1000\n",
      "#---------------------------------- \n",
      " Run AcceWeight algorithm with T =  1000 , stochastic =  True\n",
      "t= 1\n",
      "t= 501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:50: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_terminal= 1000\n",
      "#---------------------------------- \n",
      " Run EW algorithm with T =  1000 , stochastic =  True\n",
      "t= 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:47: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t= 501\n",
      "T_terminal= 1000\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------------------\n",
    "#         STOCHASTIC\n",
    "#-----------------------------------------------------------------------------------------\n",
    "#-----------------------------------\n",
    "# Choose a regime\n",
    "#-----------------------------------\n",
    "regime = 'stochastic'\n",
    "instances = np.arange(1)        #Choose the set of indices to name the instances\n",
    "\n",
    "beta = 1      # Smoothness approximation parameter of AcceleWeight\n",
    "T=1000        # Learning horizon\n",
    "theta=1000     # Controling the first step-size of AdaWeight\n",
    "\n",
    "for instance in instances:\n",
    "#-----------------------------------------------------------\n",
    "# Pre-generate and store random exo-load to data/network_name/noise.gpickle\n",
    "#----------------------------------------------------------\n",
    "    if regime=='stationary': \n",
    "        Stoch = False\n",
    "        network_noise = []\n",
    "        mean_noise = 0\n",
    "    else: \n",
    "        Stoch=True\n",
    "        bound_noise = 0.1 # Determine the range of noise ---> generate noise by Uniform[-bound_noise, bound_noise]\n",
    "        StdDev=5\n",
    "        network_noise = generate_noise(network,T,bound_noise_rel=bound_noise,StdDevNoise_abs=StdDev)\n",
    "        mean_noise = 0\n",
    "        nx.write_gpickle(network_noise,directory+'noise,N='+str(N)+', T='+ str(T)+ ', instance ='+ str(instance)+'.gpickle')   \n",
    "\n",
    "    folder = directory_sol + '/'+ regime+ '/N='+str(N)+', T='+str(T)+ ', beta = ' + str(beta)+', instance =' +str(instance)+ '/'\n",
    "    os.makedirs(os.path.dirname(folder), exist_ok=True)        \n",
    "    #-----------------------\n",
    "    # Run AdaEW algorithm\n",
    "    #-------------------------\n",
    "    SolAdaEW= AdaEW(pairs,network,paths,edges,T, theta,network_noise,mean_noise,stoch = Stoch, gamma1=0)  \n",
    "    save_potential(folder, potAdaEW=SolAdaEW.pot)      #save the potential values\n",
    "    #----------------------------\n",
    "    # Run AcceEW algorithm\n",
    "    #-------------------------   \n",
    "    SolAcceEW = AcceEW(pairs,network,paths,edges,T,network_noise,mean_noise,beta,stoch = Stoch) \n",
    "    save_potential(folder, potAcceEW=SolAcceEW.pot)      #save the potential values\n",
    "    #-----------------------\n",
    "    # Run EW algorithm\n",
    "    #-------------------------\n",
    "    SolEW= EW(pairs,network,paths,edges,T,network_noise,mean_noise,stoch = Stoch, fixed_stepsize=False, stepsize=1)\n",
    "    save_potential(folder, potEW=SolEW.pot)      #save the potential values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
