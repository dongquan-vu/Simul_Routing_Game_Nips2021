{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Adaptive Exponential Weights Algorithm for <br/> Learning Equilibrium Flows of the Routing Game</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import networkx as nx   # best working with networkx 2.5 to avoid errors\n",
    "from scipy import integrate\n",
    "import uuid   #for generating unique id for files and folders\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "current_dir= os.getcwd()\n",
    "import sys\n",
    "import openmatrix as omx\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preliminary functions for importing edges data (network_net.tntp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\dongq\\\\Google Drive\\\\2021 Works\\\\Routing game\\\\Routing-Game-MOR-Submission\\\\Simulation_python\\\\TransportationNetworks-master'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = os.path.dirname(os.path.abspath('.'))     #Look for the root folder\n",
    "root = root+'\\\\TransportationNetworks-master'\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_edge(network_name):\n",
    "    netfile = os.path.join(root, network_name,network_name + '_net.tntp')\n",
    "    net = pd.read_csv(netfile, skiprows=8, sep='\\t')\n",
    "\n",
    "    trimmed= [s.strip().lower() for s in net.columns]\n",
    "    net.columns = trimmed\n",
    "\n",
    "    # And drop the silly first andlast columns\n",
    "    net.drop(['~', ';'], axis=1, inplace=True)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create edgede list from a pandaframe parsed from tntp:\n",
    "def edge_list(net):\n",
    "    E = len(net)    #number of edges\n",
    "    edge_list = []\n",
    "    for i in range(E): edge_list.append([net['init_node'][i] , net['term_node'][i]])\n",
    "    return edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the function generating a nx.Graph from Tntp files:\n",
    "def graph_generation(network_name):\n",
    "    net = read_edge(network_name)    # Import the whole data_frame of edges data into net\n",
    "    edges = edge_list(net)           # Generate the list of edges\n",
    "    G=nx.DiGraph()                     # Create an empty nx.graph\n",
    "    G.add_edges_from(edges)  # Import edges into the nx.graph\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Respective to a set of paths, assign on each edge e the indices of paths passing e:\n",
    "def passing_edges(G,paths):\n",
    "    N = len(paths)\n",
    "    # Reset the attribute if already existed\n",
    "    for e in G.edges(): \n",
    "        edge = G[e[0]][e[1]]\n",
    "        if 'passing_paths' in edge: del edge['passing_paths']\n",
    "            \n",
    "    for i in range(N):\n",
    "        for p in range(len(paths[i])):\n",
    "            for node in range(len(paths[i][p]) -1):\n",
    "                e0= paths[i][p][node]\n",
    "                e1 = paths[i][p][node+1]\n",
    "                edge = G[e0][e1]    # elif e=(u,v) where v< u; then, its revert edge=(v,u) is in G\n",
    "                \n",
    "                if 'passing_paths' not in edge:  edge['passing_paths'] =  [[i,p]]    #If there is not yet any assigned passing_paths, create the attribute\n",
    "                else:   edge['passing_paths'].append([i,p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUnction to discover k shortest_paths from source to target:\n",
    "def k_shortest_paths(G, source, target, k, weight=None):\n",
    "    return list(islice(nx.shortest_simple_paths(G, source, target, weight=weight), k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Networks Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate g_pickle data for networks by the function ```DAG_generation()``` taking the following arguments:\n",
    "* ```network_name``` = name of the network from which the data is chosen\n",
    "* $N \\in \\mathbb{N}$ = the number of O-D pairs we want to consider\n",
    "* ```random_pairs``` = whether we randomly choose the O-D pairs or we input by a list of O-D pairs\n",
    "* ```max_paths``` = maximum number of paths in each DAG\n",
    "* ```Pairs``` = a data frame indicating the pairs in considerations\n",
    "\n",
    "The outputs are stored in \"./data/network_name\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DAG_generation(network_name, N, random_pairs = True, Pairs = [], max_paths = 600):  \n",
    "    G = graph_generation(network_name)    # Create a nx.graph of the network\n",
    "    print('Create a nx.graph of ', network_name, 'with', nx.info(G))\n",
    "    V = G.number_of_nodes()\n",
    "    if random_pairs == False: N = len(Pairs)     # If manually input the Pairs, make sure number of pairs N is correct\n",
    "    inflow = omx.open_file(root + '\\\\'+ network_name + '\\\\demand.omx') #Import the inflows data\n",
    "    pairs_data = pd.DataFrame(columns = ['source','sink','demand'])\n",
    "    Paths = [] #Intialize to store the path sets\n",
    "    \n",
    "    if random_pairs == True:\n",
    "        for i in range(N):\n",
    "            source = random.choice(list(G.nodes))        #Choose randomly a sourcce\n",
    "            while G.out_degree(source)==0: source = random.choice(list(G.nodes)) # If source has zero out_degree, re-choose it\n",
    "            sink = random.choice(list(nx.algorithms.dag.descendants(G, source)))   #randomly choose a sink reachable from source\n",
    "            # if (source,sink) coincides with previous chosen O-D pairs, redo; or if inflow[source][sink]==0, redo:\n",
    "            while ([source,sink] in Pairs) or (inflow['matrix'][source-1][sink-1]==0):       #Matrix index shifted by 1 \n",
    "                source = random.choice(list(G.nodes))\n",
    "                while G.out_degree(source)==0: source = random.choice(list(G.nodes)) # If source has zero out_degree, re-choose it\n",
    "                sink = random.choice(list(nx.algorithms.dag.descendants(G, source)))   #randomly choose a sink reachable from source\n",
    "            pairs_data.loc[i] = list([int(source), int(sink),inflow['matrix'][source-1][sink-1]])\n",
    "            print('Finish creating pairs_data of pair ',i)\n",
    "           \n",
    "            Paths_i = k_shortest_paths(G, source, sink, max_paths, weight=None)   #Find max_paths shortest paths from source to sink\n",
    "#             k = np.random.choice(max_paths+1)\n",
    "#             Paths_i = k_shortest_paths(G, source, sink, k, weight=None)   #Find max_paths shortest paths from source to sink\n",
    "            Paths.append(Paths_i)\n",
    "            print('Finish creating paths data of pair', i)\n",
    "    \n",
    "    if random_pairs ==False:\n",
    "        for i in range(N):\n",
    "            source = int(Pairs['source'][i])\n",
    "            sink = int(Pairs['sink'][i])\n",
    "            if source > V or sink > V: print('Wrong input of pairs')\n",
    "            else:\n",
    "                pairs_data.loc[i] = list([int(source), int(sink),Pairs['demand'][i]])\n",
    "                print('Finish creating pairs_data of pair ',i)\n",
    "    \n",
    "                Paths_i = k_shortest_paths(G, source, sink, max_paths, weight=None)   #Find max_paths shortest paths from source to sink\n",
    "                Paths.append(Paths_i)\n",
    "                print('Finish creating paths data of pair', i)\n",
    "    \n",
    "    #Store the pairs_data   \n",
    "    directory = current_dir+\"/data/\"+network_name+'/'\n",
    "    os.makedirs(os.path.dirname(directory), exist_ok=True)\n",
    "    pairs_data.to_csv(directory+'pairs,N='+str(N)+'.csv')\n",
    "\n",
    "    #Store the path data   \n",
    "    with open(directory+'paths,N='+str(N)+'.data', 'wb') as filehandle:\n",
    "        pickle.dump(Paths, filehandle)  # STORE the data as binary data stream into data/network_name/\n",
    "        \n",
    "     \n",
    "    print('Pre-processing the graph data')\n",
    "    # Pre-process the graph and store the graph   \n",
    "    # Assign each edge e in G with indices of the paths (relevant to the choice of pairs) passing through it\n",
    "    passing_edges(G,Paths)\n",
    "    nx.write_gpickle(G,directory +\"/graph,N=\"+ str(N)+\".gpickle\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Test: DAG generations with SiouxFalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create a nx.graph of  Austin with Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 7388\n",
      "Number of edges: 18956\n",
      "Average in degree:   2.5658\n",
      "Average out degree:   2.5658\n",
      "Finish creating pairs_data of pair  0\n",
      "Finish creating paths data of pair 0\n",
      "Finish creating pairs_data of pair  1\n",
      "Finish creating paths data of pair 1\n",
      "Finish creating pairs_data of pair  2\n",
      "Finish creating paths data of pair 2\n",
      "Finish creating pairs_data of pair  3\n",
      "Finish creating paths data of pair 3\n",
      "Finish creating pairs_data of pair  4\n",
      "Finish creating paths data of pair 4\n",
      "Finish creating pairs_data of pair  5\n",
      "Finish creating paths data of pair 5\n",
      "Finish creating pairs_data of pair  6\n",
      "Finish creating paths data of pair 6\n",
      "Finish creating pairs_data of pair  7\n",
      "Finish creating paths data of pair 7\n",
      "Finish creating pairs_data of pair  8\n",
      "Finish creating paths data of pair 8\n",
      "Finish creating pairs_data of pair  9\n",
      "Finish creating paths data of pair 9\n",
      "Pre-processing the graph data\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "DAG_generation('Austin', N, random_pairs = True, Pairs=[], max_paths = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
